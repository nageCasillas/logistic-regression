{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f222320-9c95-47e7-b4fc-3641fcacf286",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "Logistic regression is a statistical method used for binary classification, where the outcome or dependent variable is categorical (usually 0 or 1, yes or no, true or false). Unlike linear regression, which predicts continuous values, logistic regression predicts the probability that an observation belongs to a certain class. It uses the logistic (sigmoid) function to model the relationship between the independent variables and the probability of the dependent variable being in a particular class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e95f6d0-fd8e-4294-8c92-b5dac96f0fa0",
   "metadata": {},
   "source": [
    "# why linear regression cannot be used in classification?\n",
    "1) Outlier: linear regression is sensitive to outliers, and in a classification setting, extreme values in the feature space could skew the results, leading to incorrect predictions.\n",
    "2) Squash Line: Logistic regression, with its sigmoid function, ensures outputs are constrained between 0 and 1, making it more appropriate for classification tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed843aa1-7041-4ea5-a55c-d2ffe1e7955e",
   "metadata": {},
   "source": [
    "# Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2c7ad11-e959-49e4-8e6b-d9ee5e8cdec9",
   "metadata": {},
   "source": [
    "Logistic regression solves classification problems by using the sigmoid function, which maps any real-valued input into a probability between 0 and 1. The sigmoid function ensures that the output can be interpreted as a probability, making it ideal for binary classification. The model then assigns class labels based on a threshold, typically 0.5."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796ba12b-fe2a-4185-8432-79bac68a704e",
   "metadata": {},
   "source": [
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- \\( z \\) is the input to the function (linear combination of weights and features).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81cf8184-46e7-40c2-b57f-8a2ef1b738c8",
   "metadata": {},
   "source": [
    "# Log-Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b5538d8-657a-44d3-ae2c-db3bf6b04d5b",
   "metadata": {},
   "source": [
    "However, the sigmoid function creates a non-convex optimization landscape when directly used for convergence, which makes gradient descent prone to getting stuck in local minima. This is why logistic regression does not optimize the raw sigmoid function itself but instead uses a log-loss (or cross-entropy) cost function, which is convex and ensures global convergence using gradient-based optimization methods."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d4334b-dc8e-470e-8cbf-54ed93e7b908",
   "metadata": {},
   "source": [
    "$$\n",
    "\\text{Log-Loss} = -\\frac{1}{m} \\sum_{i=1}^{m} \\left[ y^{(i)} \\log(h_\\theta(x^{(i)})) + (1 - y^{(i)}) \\log(1 - h_\\theta(x^{(i)})) \\right]\n",
    "$$\n",
    "\n",
    "Where:\n",
    "- $y^{(i)}$ is the true label (0 or 1).\n",
    "- $h_\\theta(x^{(i)})$ is the predicted probability from the sigmoid function.\n",
    "- $m$ is the number of training examples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1d812ba-7de0-4140-9cae-b777d1dbcbda",
   "metadata": {},
   "source": [
    "# Perfomance Matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8a7699-b275-4fe9-b9df-63d3d6e1bcbe",
   "metadata": {},
   "source": [
    "## Confusion Matrix\n",
    "A confusion matrix is a performance measurement tool used for classification models. It provides a summary of prediction results by comparing the actual labels to the predicted labels. The matrix has four components:\n",
    "\n",
    "- True Positives (TP): Correct predictions where the model predicted the positive class correctly.\n",
    "- True Negatives (TN): Correct predictions where the model predicted the negative class correctly.\n",
    "- False Positives (FP): Incorrect predictions where the model predicted the positive class but it was actually negative (also called Type I error).\n",
    "- False Negatives (FN): Incorrect predictions where the model predicted the negative class but it was actually positive (Type II error).\n",
    "\n",
    "The confusion matrix helps evaluate classification accuracy, precision, recall, and other metrics.\n",
    "The formula of accuracy is (TP+TN)/(TP+TN+FP+FN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6cff36a-c980-42d5-b99f-67945eefeac1",
   "metadata": {},
   "source": [
    "## Precision\n",
    "Precision measures the accuracy of positive predictions. It is the ratio of true positives (TP) to the total number of positive predictions (TP + FP). Precision answers the question: \"Of all the instances predicted as positive, how many were correct?\"\n",
    "$$\n",
    "\\text{Precision} = \\frac{TP}{TP + FP}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd6c14db-31c8-45c0-bf41-fb7fd937c208",
   "metadata": {},
   "source": [
    "##  Recall\n",
    "Recall (or Sensitivity) measures how well the model identifies actual positives. It is the ratio of true positives (TP) to the total actual positives (TP + FN). Recall answers the question: \"Of all the actual positive instances, how many were correctly predicted?\"\n",
    "$$\n",
    "\\text{Recall} = \\frac{TP}{TP + FN}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7d6686-3a0b-48d2-9a41-0b59adacc6ff",
   "metadata": {},
   "source": [
    "## F-Beta Score\n",
    "F-beta score is a weighted harmonic mean of precision and recall, where the weight is determined by the parameter β. A higher β values gives more importance to recall, while lower β gives more weight to precision. The most common case is the F1 score (β = 1), which balances both precision and recall equally.\n",
    "$$\n",
    "F_{\\beta} = (1 + \\beta^2) \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{(\\beta^2 \\cdot \\text{Precision}) + \\text{Recall}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0dd9cf9-d664-4198-ab56-86f97c134d48",
   "metadata": {},
   "source": [
    "### F-1 Score\n",
    "The F1 score is the harmonic mean of precision and recall, with equal importance given to both (β = 1). It is widely used when precision and recall are equally important and you want to balance both.\n",
    "$$\n",
    "F_1 = 2 \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{\\text{Precision} + \\text{Recall}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2934755e-a0e9-4b6d-9047-d6de54570814",
   "metadata": {},
   "source": [
    "### F-0.5 Score\n",
    "This score gives more weight to precision over recall. A low β value like 0.5 favors models that make fewer false positive errors, meaning precision is prioritized. It is useful when false positives are more costly than false negatives.\n",
    "$$\n",
    "F_{0.5} = (1 + 0.5^2) \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{(0.5^2 \\cdot \\text{Precision}) + \\text{Recall}}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ec46f0-ee12-46b7-85e1-62809402f140",
   "metadata": {},
   "source": [
    "### F-2 Score\n",
    "This score gives more weight to recall over precision (β = 2). It is useful when false negatives are more costly than false positives, meaning that identifying as many positives as possible is more important than avoiding false alarms.\n",
    "$$\n",
    "F_2 = (1 + 2^2) \\cdot \\frac{\\text{Precision} \\cdot \\text{Recall}}{(2^2 \\cdot \\text{Precision}) + \\text{Recall}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba0c6c3-446d-4f0a-9ecd-f3efd6ca1923",
   "metadata": {},
   "source": [
    "# Logistic Regression one versus Rest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8126a2e6-2dcb-49de-a640-e4f29158474a",
   "metadata": {},
   "source": [
    "**One-vs-Rest (OvR)** is a strategy used in **logistic regression** to extend the binary classification model to handle **multiclass classification** problems. In this approach, a separate binary classifier is trained for each class. Each classifier treats one class as the positive class (label 1) and all other classes as the negative class (label 0).\n",
    "\n",
    "For a dataset with \\(n\\) classes, OvR creates \\(n\\) logistic regression models. During prediction, each model outputs a probability, and the class with the highest probability is chosen as the final prediction. \n",
    "\n",
    "This method is simple and widely used because it allows logistic regression to work with multiclass data while maintaining the advantages of the binary classifier."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
